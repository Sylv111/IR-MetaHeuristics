{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "\n",
    "class WeightLogger(Callback):\n",
    "    def __init__(self, layer_name=\"lstm\"):\n",
    "        super().__init__()\n",
    "        self.layer_name = layer_name\n",
    "        self.weights_per_epoch = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # On récupère la couche par nom\n",
    "        for layer in self.model.layers:\n",
    "            if self.layer_name in layer.name.lower():\n",
    "                weights = layer.get_weights()[0]  # poids des entrées\n",
    "                self.weights_per_epoch.append(weights.copy())\n",
    "                break\n",
    "            \n",
    "            \n",
    "# === 1. Chargement des données ===\n",
    "df = pd.read_csv(\"scaled_dataset.csv\")  # Remplace par ton CSV réel\n",
    "#df = pd.read_csv(\"../DataCleaning/A - CSV par bâtiment/batiment_1.csv\")  # Remplace par ton CSV réel\n",
    "\n",
    "# === 2. Normalisation ===\n",
    "scaler = MinMaxScaler()\n",
    "scaled_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "y_scaled = scaled_df['production']\n",
    "X_scaled = scaled_df.drop(columns=['production'])\n",
    "\n",
    "# === 3. Création des séquences temporelles ===\n",
    "def create_sequences(X, y, window_size=7):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - window_size):\n",
    "        Xs.append(X[i:i + window_size])\n",
    "        ys.append(y[i + window_size])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "window_size = 21\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, window_size)\n",
    "\n",
    "# === 4. Split train/test ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# === 5. Définition du modèle LSTM ===\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    LSTM(32),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer=Adam(0.001), loss='mae')\n",
    "\n",
    "# === 6. Entraînement ===\n",
    "weight_logger = WeightLogger(layer_name=\"lstm\")  # nom de la couche\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=700,  \n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    callbacks=[weight_logger]\n",
    ")\n",
    "# === 7. Prediction ===\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# Inverse scaling des prédictions\n",
    "n_features = scaled_df.shape[1]\n",
    "dummy = np.zeros((len(y_pred), n_features))\n",
    "target_idx = scaled_df.columns.get_loc('production')  # ou passe target_col en argument\n",
    "dummy[:, target_idx] = y_pred\n",
    "y_pred_real = scaler.inverse_transform(dummy)[:, target_idx]\n",
    "\n",
    "dummy_test = np.zeros((len(y_test), n_features))\n",
    "dummy_test[:, target_idx] = y_test\n",
    "y_test_real = scaler.inverse_transform(dummy_test)[:, target_idx]\n",
    "\n",
    "mae = mean_absolute_error(y_test_real, y_pred_real)\n",
    "mse = np.mean((y_test_real - y_pred_real) ** 2)\n",
    "r2 = r2_score(y_test_real, y_pred_real)\n",
    "\n",
    "\n",
    "\n",
    "# === 8. Affichage ===\n",
    "\n",
    "#Poids des parametres\n",
    "# Prendre le poids [0, 0] (entrée 0 → cellule 0)\n",
    "w00 = [w[0, 0] for w in weight_logger.weights_per_epoch]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(w00)\n",
    "plt.xlabel(\"Époque\")\n",
    "plt.ylabel(\"Valeur du poids [0,0]\")\n",
    "plt.title(\"Évolution du poids (entrée 0 → cellule 0) dans la couche LSTM\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Courbe loss \n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Courbe de Loss (MAE) par époque')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Performance du modèle\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_real, label=\"Vrai\")\n",
    "plt.plot(y_pred_real, label=\"Prévu\")\n",
    "plt.legend()\n",
    "plt.title(f\"LSTM - MAE: {mae:.4f} | R²: {r2:.4f}| MSE: {mse:.4f}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 1. Scatter plot (prédictions vs réel)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test_real, y_pred_real, alpha=0.7, color='orange')\n",
    "plt.plot([min(y_test_real), max(y_test_real)], [min(y_test_real), max(y_test_real)], 'r--', label=\"Idéal (y = ŷ)\")\n",
    "plt.xlabel(\"Valeurs réelles (y)\")\n",
    "plt.ylabel(\"Prédictions (ŷ)\")\n",
    "plt.title(\"Prédictions vs Réel\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "StatsDf = pd.DataFrame({\n",
    "    \"Y_test\": y_test_real,\n",
    "    \"Y_pred\": y_pred_real,\n",
    "    \"Error\": y_test_real - y_pred_real,\n",
    "    \"Error_Percent\": abs(y_test_real - y_pred_real) / y_test_real * 100\n",
    "})\n",
    "\n",
    "print(StatsDf.describe())\n",
    "\n",
    "StatsDf['Error'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abddd94-0455-46cb-9e97-ed1532f1575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "\n",
    "class WeightLogger(Callback):\n",
    "    def __init__(self, layer_name=\"lstm\"):\n",
    "        super().__init__()\n",
    "        self.layer_name = layer_name\n",
    "        self.weights_per_epoch = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # On récupère la couche par nom\n",
    "        for layer in self.model.layers:\n",
    "            if self.layer_name in layer.name.lower():\n",
    "                weights = layer.get_weights()[0]  # poids des entrées\n",
    "                self.weights_per_epoch.append(weights.copy())\n",
    "                break\n",
    "            \n",
    "            \n",
    "# === 1. Chargement des données ===\n",
    "df = pd.read_csv(\"full_dataset.csv\",sep=\";\")  # Remplace par ton CSV réel\n",
    "# 1.1 Conversion de la colonne date\n",
    "df['date1'] = pd.to_datetime(df['date'], dayfirst=True)\n",
    "\n",
    "# 1.2 Création des features temporelles cycliques\n",
    "df['dayofweek'] = df['date1'].dt.dayofweek\n",
    "df['month'] = df['date1'].dt.month\n",
    "\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "\n",
    "df.drop(columns=['month', 'dayofweek'], inplace=True)\n",
    "\n",
    "# 1.3 Supprimer les colonnes non numériques avant normalisation\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# === 2. Normalisation ===\n",
    "scaler = MinMaxScaler()\n",
    "scaled_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "y_scaled = scaled_df['production']\n",
    "X_scaled = scaled_df.drop(columns=['production'])\n",
    "\n",
    "# === 3. Création des séquences temporelles ===\n",
    "def create_sequences(X, y, window_size=7):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - window_size):\n",
    "        Xs.append(X[i:i + window_size])\n",
    "        ys.append(y[i + window_size])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "window_size = 21\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, window_size)\n",
    "\n",
    "# === 4. Split train/test ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# === 5. Définition du modèle LSTM ===\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    LSTM(32),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer=Adam(0.001), loss='mae')\n",
    "\n",
    "# === 6. Entraînement ===\n",
    "weight_logger = WeightLogger(layer_name=\"lstm\")  # nom de la couche\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=700,  \n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    callbacks=[weight_logger]\n",
    ")\n",
    "# === 7. Prediction ===\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# Inverse scaling des prédictions\n",
    "n_features = scaled_df.shape[1]\n",
    "dummy = np.zeros((len(y_pred), n_features))\n",
    "target_idx = scaled_df.columns.get_loc('production')  # ou passe target_col en argument\n",
    "dummy[:, target_idx] = y_pred\n",
    "y_pred_real = scaler.inverse_transform(dummy)[:, target_idx]\n",
    "\n",
    "dummy_test = np.zeros((len(y_test), n_features))\n",
    "dummy_test[:, target_idx] = y_test\n",
    "y_test_real = scaler.inverse_transform(dummy_test)[:, target_idx]\n",
    "\n",
    "mae = mean_absolute_error(y_test_real, y_pred_real)\n",
    "mse = np.mean((y_test_real - y_pred_real) ** 2)\n",
    "r2 = r2_score(y_test_real, y_pred_real)\n",
    "\n",
    "\n",
    "\n",
    "# === 8. Affichage ===\n",
    "\n",
    "#Poids des parametres\n",
    "# Prendre le poids [0, 0] (entrée 0 → cellule 0)\n",
    "w00 = [w[0, 0] for w in weight_logger.weights_per_epoch]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(w00)\n",
    "plt.xlabel(\"Époque\")\n",
    "plt.ylabel(\"Valeur du poids [0,0]\")\n",
    "plt.title(\"Évolution du poids (entrée 0 → cellule 0) dans la couche LSTM\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Courbe loss \n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Courbe de Loss (MAE) par époque')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Performance du modèle\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_real, label=\"Vrai\")\n",
    "plt.plot(y_pred_real, label=\"Prévu\")\n",
    "plt.legend()\n",
    "plt.title(f\"LSTM - MAE: {mae:.4f} | R²: {r2:.4f}| MSE: {mse:.4f}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 1. Scatter plot (prédictions vs réel)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test_real, y_pred_real, alpha=0.7, color='orange')\n",
    "plt.plot([min(y_test_real), max(y_test_real)], [min(y_test_real), max(y_test_real)], 'r--', label=\"Idéal (y = ŷ)\")\n",
    "plt.xlabel(\"Valeurs réelles (y)\")\n",
    "plt.ylabel(\"Prédictions (ŷ)\")\n",
    "plt.title(\"Prédictions vs Réel\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "StatsDf = pd.DataFrame({\n",
    "    \"Y_test\": y_test_real,\n",
    "    \"Y_pred\": y_pred_real,\n",
    "    \"Error\": y_test_real - y_pred_real,\n",
    "    \"Error_Percent\": abs(y_test_real - y_pred_real) / y_test_real * 100\n",
    "})\n",
    "\n",
    "print(StatsDf.describe())\n",
    "\n",
    "StatsDf['Error'].hist(bins=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

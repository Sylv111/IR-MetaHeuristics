{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# === CALLBACK pour suivre les poids ===\n",
    "class WeightLogger(Callback):\n",
    "    def __init__(self, layer_name=\"lstm\"):\n",
    "        super().__init__()\n",
    "        self.layer_name = layer_name\n",
    "        self.weights_per_epoch = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for layer in self.model.layers:\n",
    "            if self.layer_name in layer.name.lower():\n",
    "                weights = layer.get_weights()[0]\n",
    "                self.weights_per_epoch.append(weights.copy())\n",
    "                break\n",
    "\n",
    "# === 1. Chargement des données ===\n",
    "def load_data(csv_path, ws):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    y_scaled = scaled_df['production']\n",
    "    X_scaled = scaled_df.drop(columns=['production'])\n",
    "\n",
    "    def create_sequences(X, y, window_size=21):\n",
    "        Xs, ys = [], []\n",
    "        for i in range(len(X) - window_size):\n",
    "            Xs.append(X[i:i + window_size])\n",
    "            ys.append(y[i + window_size])\n",
    "        return np.array(Xs), np.array(ys)\n",
    "\n",
    "    X_seq, y_seq = create_sequences(X_scaled, y_scaled, ws)\n",
    "    return X_seq, y_seq, scaler, scaled_df\n",
    "\n",
    "# === 2. Model ConvLSTM1D ===\n",
    "def model_convlstm1d(X_seq, y_seq, epoch, batch_sizes):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n",
    "        LSTM(64, return_sequences=False),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss='mae')\n",
    "\n",
    "    weight_logger = WeightLogger(layer_name=\"lstm\")\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epoch,\n",
    "        batch_size=batch_sizes,\n",
    "        validation_split=0.1,\n",
    "        verbose=1,\n",
    "        callbacks=[weight_logger]\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "    return model, history, y_pred, y_test, weight_logger\n",
    "\n",
    "# === 3. Performance model ===\n",
    "def plot_function(scaled_data, y_pred, y_test, scaler, weight_logger, history):\n",
    "    n_features = scaled_data.shape[1]\n",
    "    dummy = np.zeros((len(y_pred), n_features))\n",
    "    target_idx = scaled_data.columns.get_loc('production')\n",
    "    dummy[:, target_idx] = y_pred\n",
    "    y_pred_real = scaler.inverse_transform(dummy)[:, target_idx]\n",
    "\n",
    "    dummy_test = np.zeros((len(y_test), n_features))\n",
    "    dummy_test[:, target_idx] = y_test\n",
    "    y_test_real = scaler.inverse_transform(dummy_test)[:, target_idx]\n",
    "\n",
    "    mae = mean_absolute_error(y_test_real, y_pred_real)\n",
    "    mse = np.mean((y_test_real - y_pred_real) ** 2)\n",
    "    r2 = r2_score(y_test_real, y_pred_real)\n",
    "\n",
    "    w00 = [w[0, 0] for w in weight_logger.weights_per_epoch]\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(w00)\n",
    "    plt.xlabel(\"Époque\")\n",
    "    plt.ylabel(\"Valeur du poids [0,0]\")\n",
    "    plt.title(\"Évolution du poids (entrée 0 → cellule 0) dans la couche LSTM\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Courbe de Loss (MAE) par époque')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test_real, label=\"Vrai\")\n",
    "    plt.plot(y_pred_real, label=\"Prévu\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Conv1D + LSTM - MAE: {mae:.4f} | R²: {r2:.4f} | MSE: {mse:.4f}\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(y_test_real, y_pred_real, alpha=0.7, color='orange')\n",
    "    plt.plot([min(y_test_real), max(y_test_real)], [min(y_test_real), max(y_test_real)], 'r--', label=\"Idéal (y = ŷ)\")\n",
    "    plt.xlabel(\"Valeurs réelles (y)\")\n",
    "    plt.ylabel(\"Prédictions (ŷ)\")\n",
    "    plt.title(\"Prédictions vs Réel\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return mae, mse, r2, y_test_real, y_pred_real\n",
    "\n",
    "# === 4. Main ===\n",
    "def main():\n",
    "    csv_path = \"scaled_dataset.csv\"\n",
    "    window_size = 21\n",
    "    X_seq, y_seq, scaler, scaled_data = load_data(csv_path, window_size)\n",
    "    model, history, y_pred, y_test, weight_logger = model_convlstm1d(X_seq, y_seq, epoch=700, batch_sizes=32)\n",
    "    mae, mse, r2, y_test_real, y_pred_real = plot_function(scaled_data, y_pred, y_test, scaler, weight_logger, history)\n",
    "    print(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "\n",
    "    StatsDf = pd.DataFrame({\n",
    "        \"Y_test\": y_test_real,\n",
    "        \"Y_pred\": y_pred_real,\n",
    "        \"Error\": y_test_real - y_pred_real,\n",
    "        \"Error_Percent\": abs(y_test_real - y_pred_real) / y_test_real * 100\n",
    "    })\n",
    "\n",
    "    print(StatsDf.describe())\n",
    "    StatsDf['Error'].hist(bins=100)\n",
    "    plt.title(\"Distribution de l'erreur\")\n",
    "    plt.xlabel(\"Erreur absolue\")\n",
    "    plt.ylabel(\"Fréquence\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fd7f17-0aa1-4e8a-99fc-c64a1db64fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# === CALLBACK pour suivre les poids ===\n",
    "class WeightLogger(Callback):\n",
    "    def __init__(self, layer_name=\"lstm\"):\n",
    "        super().__init__()\n",
    "        self.layer_name = layer_name\n",
    "        self.weights_per_epoch = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for layer in self.model.layers:\n",
    "            if self.layer_name in layer.name.lower():\n",
    "                weights = layer.get_weights()[0]\n",
    "                self.weights_per_epoch.append(weights.copy())\n",
    "                break\n",
    "\n",
    "# === 1. Chargement des données ===\n",
    "def load_data(csv_path, ws):\n",
    "    df = pd.read_csv(csv_path, sep=';')\n",
    "    df['date1'] = pd.to_datetime(df['date'], dayfirst=True)\n",
    "\n",
    "    df['dayofweek'] = df['date1'].dt.dayofweek\n",
    "    df['month'] = df['date1'].dt.month\n",
    "\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "\n",
    "    df.drop(columns=['month', 'dayofweek'], inplace=True)\n",
    "    df = df.select_dtypes(include=[np.number])\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    y_scaled = scaled_df['production']\n",
    "    X_scaled = scaled_df.drop(columns=['production'])\n",
    "\n",
    "    def create_sequences(X, y, window_size=21):\n",
    "        Xs, ys = [], []\n",
    "        for i in range(len(X) - window_size):\n",
    "            Xs.append(X[i:i + window_size])\n",
    "            ys.append(y[i + window_size])\n",
    "        return np.array(Xs), np.array(ys)\n",
    "\n",
    "    X_seq, y_seq = create_sequences(X_scaled, y_scaled, ws)\n",
    "    return X_seq, y_seq, scaler, scaled_df\n",
    "\n",
    "# === 2. Model ConvLSTM1D ===\n",
    "def model_convlstm1d(X_seq, y_seq, epoch, batch_sizes):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n",
    "        LSTM(64, return_sequences=False),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss='mae')\n",
    "\n",
    "    weight_logger = WeightLogger(layer_name=\"lstm\")\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epoch,\n",
    "        batch_size=batch_sizes,\n",
    "        validation_split=0.1,\n",
    "        verbose=1,\n",
    "        callbacks=[weight_logger]\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "    return model, history, y_pred, y_test, weight_logger\n",
    "\n",
    "# === 3. Performance model ===\n",
    "def plot_function(scaled_data, y_pred, y_test, scaler, weight_logger, history):\n",
    "    n_features = scaled_data.shape[1]\n",
    "    dummy = np.zeros((len(y_pred), n_features))\n",
    "    target_idx = scaled_data.columns.get_loc('production')\n",
    "    dummy[:, target_idx] = y_pred\n",
    "    y_pred_real = scaler.inverse_transform(dummy)[:, target_idx]\n",
    "\n",
    "    dummy_test = np.zeros((len(y_test), n_features))\n",
    "    dummy_test[:, target_idx] = y_test\n",
    "    y_test_real = scaler.inverse_transform(dummy_test)[:, target_idx]\n",
    "\n",
    "    mae = mean_absolute_error(y_test_real, y_pred_real)\n",
    "    mse = np.mean((y_test_real - y_pred_real) ** 2)\n",
    "    r2 = r2_score(y_test_real, y_pred_real)\n",
    "\n",
    "    w00 = [w[0, 0] for w in weight_logger.weights_per_epoch]\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(w00)\n",
    "    plt.xlabel(\"Époque\")\n",
    "    plt.ylabel(\"Valeur du poids [0,0]\")\n",
    "    plt.title(\"Évolution du poids (entrée 0 → cellule 0) dans la couche LSTM\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Courbe de Loss (MAE) par époque')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_test_real, label=\"Vrai\")\n",
    "    plt.plot(y_pred_real, label=\"Prévu\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Conv1D + LSTM - MAE: {mae:.4f} | R²: {r2:.4f} | MSE: {mse:.4f}\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(y_test_real, y_pred_real, alpha=0.7, color='orange')\n",
    "    plt.plot([min(y_test_real), max(y_test_real)], [min(y_test_real), max(y_test_real)], 'r--', label=\"Idéal (y = ŷ)\")\n",
    "    plt.xlabel(\"Valeurs réelles (y)\")\n",
    "    plt.ylabel(\"Prédictions (ŷ)\")\n",
    "    plt.title(\"Prédictions vs Réel\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return mae, mse, r2, y_test_real, y_pred_real\n",
    "\n",
    "# === 4. Main ===\n",
    "def main():\n",
    "    csv_path = \"full_dataset.csv\"\n",
    "    window_size = 21\n",
    "    X_seq, y_seq, scaler, scaled_data = load_data(csv_path, window_size)\n",
    "    model, history, y_pred, y_test, weight_logger = model_convlstm1d(X_seq, y_seq, epoch=700, batch_sizes=32)\n",
    "    mae, mse, r2, y_test_real, y_pred_real = plot_function(scaled_data, y_pred, y_test, scaler, weight_logger, history)\n",
    "    print(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "\n",
    "    error_percent = np.divide(\n",
    "        np.abs(y_test_real - y_pred_real),\n",
    "        y_test_real,\n",
    "        out=np.full_like(y_test_real, np.nan),\n",
    "        where=y_test_real != 0\n",
    "    ) * 100\n",
    "\n",
    "    StatsDf = pd.DataFrame({\n",
    "        \"Y_test\": y_test_real,\n",
    "        \"Y_pred\": y_pred_real,\n",
    "        \"Error\": y_test_real - y_pred_real,\n",
    "        \"Error_Percent\": error_percent\n",
    "    })\n",
    "\n",
    "    print(StatsDf.describe())\n",
    "    StatsDf['Error'].hist(bins=100)\n",
    "    plt.title(\"Distribution de l'erreur\")\n",
    "    plt.xlabel(\"Erreur absolue\")\n",
    "    plt.ylabel(\"Fréquence\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
